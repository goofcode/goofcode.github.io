---
title: 여러 가지 유사도 측정법 (Similarity Measure)
slug: similarity measure
thumbnail: assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/6A7407B4-99F6-4622-82BB-21E7463D61F4.png
tags: [블로그,수학,유사도]
---
  

 유사도(similarity)란 두 데이터가 얼마나 같은지 나타내주는 척도입니다. 모든 분야에서 데이터 간의 유사도를 측정하는 것은 중요하지만, 특히 데이터 과학에서 clustering, classification의 가장 기반이 되는 것이며 이를 통해서 더 복잡한 것들을 할 수 있게 해줍니다. 예를 들어 이메일 사용자가 특정 메일을 스팸 메일로 분류하였다면, 이 메일과 유사도가 높은 즉, 비슷한 메일들은 스팸 메일일 확률이 높을 것입니다. 그렇다면 두 데이터 간의 유사도는 어떻게 측정하여야 할까요?

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/6A7407B4-99F6-4622-82BB-21E7463D61F4.png)

 어떤 데이터가 n차원 상의 벡터로 표현된다면, 두 데이터의 유사도는 n차원 상에서 두 벡터 사이의 거리(distance)라고도 볼 수 있습니다. 만약 두 벡터가 가깝다면 두 데이터는 꽤나 유사한 것이고, 멀리 있다면 데이터가 서로 다르다고 얘기할 수 있겠습니다. 간단하게 2차원인 지도를 생각해볼 수 있겠죠. 지도 내의 한 위치(데이터)는 위도와 경도라는 2차원 데이터로 표현되고, 지도 상의 두 개의 점이 가까이 있다는 것은 같은 국가, 같은 지역, 같은 동네와 같이 유사성이 높다는 것을 의미하고 반대로 멀리 있다는 것은 다른 국가, 다른 지역, 다른 지역과 같이 두 위치의 유사성이 낮다는 것을 의미합니다. 이를 3차원으로 확장해도 마찬가지 입니다.

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/330px-Euclidean_distance_3d_2_cropped.png)

하지만 생각해보면 거리를 어떻게 측정하냐에 따라서 데이터의 유사도를 잘 측정할 수도 있고 그렇지 않을 수도 있습니다. 따라서 몇가지 유명한 유사도 측정법을 정리하려 합니다.

## Euclidean Distance
가장 흔히 생각할 수 있는 방법입니다. 실제 거리라는 의미에 가장 부합하는 측정법인데, 바로 두 벡터 간의 직선 거리를 측정하는 것이죠. 

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/Euclidean_distance.png)

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/330px-Euclidean_distance_3d_2_cropped%202.png)

n 차원으로 확장하면, 주어진 점 p, q에 대해 피타고라스 정리를 사용하여 다음과 같이 계산할 수 있습니다.

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/FAD95F36-0DDA-45BC-99A8-9FFD0B73B1F2.png)

## Manhattan Distance 
맨해튼과 같이 정사각형 나뉜 곳에서 두 점 사이의 거리를 측정하는 방법입니다. 두 벡터의 Cartesian coordinate의 차의 절대값의 합입니다. 아래 그림에서, 빨간색, 파란색, 노란색 선은 모두 맨해튼 거리를 나타내는 것이고, 초록색은 유클리드 거리를 나타냅니다.

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/320px-Manhattan_distance.svg.png)

n 차원으로 확장하면 다음과 같이 계산할 수 있습니다. 

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/36A6E42A-1462-4058-ADA9-04BD545FF8E0.png)

## Minkowski Distance
민코프스키 거리는 위 두 가지 거리(유클리드 거리와 맨해튼 거리)를 일반화한 것입니다. n 차원 점 X, Y에 대해 p차 민코프스키 거리는 다음과 같습니다.

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/8B721D6E-8B7C-4D19-8C1C-9BA59CF35641.png)

* p = 1일 경우 맨해튼 거리와 동일하고, L1 norm이라고도 합니다.
* p = 2일 경우 유클리드 거리와 동일하고, L2 norm이라고도 합니다.
* p = ∞일 경우 체비쇼프 거리(Chebyshev Distance)와 동일하고 L max norm이라고도 합니다.

다음은 p 값에 따라 달라지는 단위원을 그린 것입니다. 

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/2D_unit_balls.svg.png)

## Cosine Similarity
코사인 유사도는 두 벡터가 이루는 각도를 통해 유사도를 측정하는 방식입니다. 두 벡터가 이루는 각이 작을 수록 유사도가 높은 것이고, 각이 클수록 유사도가 작다고 생각하는 것입니다. 따라서 이 방식은 벡터의 크기를 고려하고 싶지 않을 때 사용할 수 있습니다. 

두 벡터가 이루는 각의 코사인 값을 통해 유사도를 측정하기 때문에, 코사인 유사도는 각이 작을수록 1에 가까워지고, 각이 클수록 -1에 가까워집니다.

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/download.png)

![](/assets/img/%E1%84%8B%E1%85%A7%E1%84%85%E1%85%A5%20%E1%84%80%E1%85%A1%E1%84%8C%E1%85%B5%20%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%20%E1%84%8E%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%20(Similarity%20Measure)/cosinesimilarityfq1.png)

왼쪽 그림에서는 이루는 각이 0도에 가깝기 때문에 코사인 유사도가 1에 가까운 반면, 오른쪽 그림은 각이 180도에 가까워 -1에 가까운 유사도를 갖습니다. 가운데 그림과 같은 경우, 이루는 각이 90도에 가깝기 때문에 유사도가 0에 가깝습니다.

